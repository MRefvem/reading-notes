# Read:42 Ethics

## Ethics in the workplace
## Article: "The code I'm still ashamed of"

Bill Sourour talks about a time in his career where he was forced to make some tough ethical decisions. Mr. Sournour, having recently been employed by a marking firm for large pharmaceutical companies, recounts an experience where he worked on a website that recommended a type of drug for clients based on the results of a quiz. However the difficult thing was that the employer didn't provide any information to him as to which drugs would be recommended to the potential client at the end of the quiz. He programmed the test to result in the answer suggesting that the client be prescribed the drug they were already receiving for their normla treatment. It turns out that one of the girls who had taken the quiz he designed committed suicide as the drug she was taking caused her severe depression and suicidal thoughts. Mr. Sourour goes on to warn that as developers we are often one of the last lines of defense against potentially dangerous and unethical practices. It's not hard to imagine that software will eventually recommend prescription drugs to patients more often in the future.

## Ethics in Technology
## Article: "Big Data is our Civil Rights issue"

The author here describes what he calls the "tree V's of data": Volume, Variety and Velocity. You can have any two of these categories at once but having all three is difficult and expensive. The advent of cloud storage means that holding data is a lot more inexpensive today than before.

The act of deciding that to store and how to store it is called designing the schema. It's the moment where someone decides what the data is about. You decide what data is about the moment you define its schema.

The issue with this philosophy is that it leads to a "collect first, ask questions later" type of philosophy that has the power to negatively impact people's lives. Collecting information about people before we even decide what it is for means that that information is liable to being misused. "Personalization" is another word for discrimination. We're not discriminating if we tailor things to you based on what we know about you - right? That's just better service.

Articles like OKCupid's "The Real Stuff White People Like" shows how easy it is to use information to guess a person's race. It's part of the way tech companies are able to personalize their marketing efforts towards clients, but is it necessarily right to be profiled in this way?

For example, you might assume tech companies are collecting information about you to suggest maybe products you might like based on your interests, but what if they start using that information as a way to potentially deny you a loan? Then...is it right?

Another example, publicly available last name information can be used as a way to generate racial boundary maps.